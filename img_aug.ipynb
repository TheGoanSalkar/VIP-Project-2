{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"img_aug.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyO7cjptdx8H7CMlVqW19+M7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"XOWPqlucamZ0","executionInfo":{"status":"ok","timestamp":1651177810549,"user_tz":240,"elapsed":8904,"user":{"displayName":"Kalyan Salkar","userId":"06157821588865164860"}}},"outputs":[],"source":["import torch\n","import os\n","from torch.utils.data import Dataset\n","from skimage import io\n","import pandas as pd\n","\n","class CrackSet(Dataset):\n","    def __init__(self, csv_file, root_dir, transform=None):\n","        self.annotations = pd.read_csv(csv_file)\n","        self.root_dir = root_dir\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.annotations)\n","\n","    def __getitem__(self, index):\n","        img_path = os.path.join(self.root_dir, self.annotations.iloc[index, 0])\n","        image = io.imread(img_path)\n","        y_label = torch.tensor(int(self.annotations.iloc[index, 1]))\n","\n","        if self.transform:\n","            image = self.transform(image)\n","\n","        return (image, y_label)"]}]}